{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e0c28d6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c933d8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "/mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib/python3.6/site-packages/torchvision/_C.so: undefined symbol: _ZN5torch8autograd4Node20get_next_sequence_nrEv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b2caf09e9f33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdalle_pytorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiscreteVAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOpenAIDiscreteVAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVQGanVAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWARHOL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdalle_pytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHugTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYttmTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChineseTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdalle_pytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextImageDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/warhol/DALLE-pytorch/dalle_pytorch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdalle_pytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdalle_pytorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWARHOL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDALLE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDiscreteVAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdalle_pytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvae\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIDiscreteVAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVQGanVAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/warhol/DALLE-pytorch/dalle_pytorch/dalle_pytorch.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdalle_pytorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributed_utils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdalle_pytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvae\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIDiscreteVAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVQGanVAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdalle_pytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDivideMax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/warhol/DALLE-pytorch/dalle_pytorch/vae.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0momegaconf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOmegaConf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtaming\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvqgan\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVQModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGumbelVQ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib64/python3.6/site-packages/taming/models/vqgan.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtaming\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minstantiate_from_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib64/python3.6/site-packages/pytorch_lightning/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallback\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLightningDataModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLightningModule\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib64/python3.6/site-packages/pytorch_lightning/callbacks/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpruning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelPruning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuantizationAwareTraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_weight_avg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStochasticWeightAveraging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib64/python3.6/site-packages/pytorch_lightning/callbacks/stochastic_weight_avg.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_get_default_scheduler_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_TORCH_GREATER_EQUAL_1_6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank_zero_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank_zero_warn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMisconfigurationException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib64/python3.6/site-packages/pytorch_lightning/trainer/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \"\"\"\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseed_everything\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib64/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelSummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_result\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLightningLoggerBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlugin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClusterEnvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib64/python3.6/site-packages/pytorch_lightning/loggers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneptune\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_NEPTUNE_AVAILABLE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNeptuneLogger\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_tube\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_TESTTUBE_AVAILABLE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTestTubeLogger\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwandb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_WANDB_AVAILABLE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWandbLogger\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_COMET_AVAILABLE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib64/python3.6/site-packages/pytorch_lightning/loggers/wandb.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwandb_run\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib64/python3.6/site-packages/wandb/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtermsetup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtermlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtermerror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtermwarn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msdk\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwandb_sdk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib64/python3.6/site-packages/wandb/sdk/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwandb_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwandb_history\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHistory\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwandb_init\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_attach\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwandb_login\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogin\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwandb_require\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequire\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib64/python3.6/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwandb_login\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwandb_setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mipython\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtelemetry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRunDisabled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSummaryDisabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib64/python3.6/site-packages/wandb/sdk/backend/backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterfaceBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface_queue\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterfaceQueue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwandb_internal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwandb_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_Manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwandb_settings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSettings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib64/python3.6/site-packages/wandb/sdk/internal/internal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minternal_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msender\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msettings_static\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib64/python3.6/site-packages/wandb/sdk/internal/sender.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilesync\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdir_watcher\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDirWatcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwandb_internal_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib64/python3.6/site-packages/wandb/filesync/dir_watcher.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mwd_polling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvendor_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"watchdog.observers.polling\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mwd_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvendor_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"watchdog.events\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib64/python3.6/site-packages/wandb/util.py\u001b[0m in \u001b[0;36mvendor_import\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvendor_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mreset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvendor_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0mreset_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib64/python3.6/site-packages/wandb/vendor/watchdog/observers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mplatform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_linux\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minotify\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInotifyObserver\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mObserver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mUnsupportedLibc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpolling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPollingObserver\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mObserver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib64/python3.6/site-packages/wandb/vendor/watchdog/observers/inotify.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minotify_buffer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInotifyBuffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m from watchdog.observers.api import (\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib64/python3.6/site-packages/wandb/vendor/watchdog/observers/inotify_buffer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwatchdog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseThread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwatchdog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayed_queue\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDelayedQueue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwatchdog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minotify_c\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInotify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib64/python3.6/site-packages/wandb/vendor/watchdog/observers/inotify_c.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mlibc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_libc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inotify_init'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib64/python3.6/site-packages/wandb/vendor/watchdog/observers/inotify_c.py\u001b[0m in \u001b[0;36m_load_libc\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlibc_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibc_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# Fallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: /mnt/nfs/home/u.tanielian/product_gen/DALLE-pytorch/venv2/lib/python3.6/site-packages/torchvision/_C.so: undefined symbol: _ZN5torch8autograd4Node20get_next_sequence_nrEv"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from ipywidgets import widgets\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from einops import repeat\n",
    "import clip\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from dalle_pytorch import DiscreteVAE, OpenAIDiscreteVAE, VQGanVAE, WARHOL\n",
    "from dalle_pytorch.tokenizer import tokenizer, HugTokenizer, YttmTokenizer, ChineseTokenizer\n",
    "from dalle_pytorch.loader import TextImageDataset\n",
    "import os\n",
    "import locale\n",
    "os.environ[\"PYTHONIOENCODING\"] = \"utf-8\"\n",
    "print(\"Imports done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35054773",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3fa8a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54870b0c226434399cdaf0bcdc7dbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='f.name', description='Username:', placeholder='Type something')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "username = widgets.Text(\n",
    "    value='f.name',\n",
    "    placeholder='Type something',\n",
    "    description='Username:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8179da3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data downloaded\n",
      "Cloning into 'Real-ESRGAN'...\n",
      "remote: Enumerating objects: 407, done.\u001b[K\n",
      "remote: Counting objects: 100% (407/407), done.\u001b[K\n",
      "remote: Compressing objects: 100% (265/265), done.\u001b[K\n",
      "remote: Total 407 (delta 220), reused 276 (delta 108), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (407/407), 3.20 MiB | 13.44 MiB/s, done.\n",
      "Resolving deltas: 100% (220/220), done.\n",
      "--2021-11-30 18:42:32--  https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github-releases.githubusercontent.com/387326890/08f0e941-ebb7-48f0-9d6a-73e87b710e7e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211130%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211130T184232Z&X-Amz-Expires=300&X-Amz-Signature=57eb066d49a526ea8e2a0b678053f62746782abb78e1ba3ac88249dd6eacd3fd&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=387326890&response-content-disposition=attachment%3B%20filename%3DRealESRGAN_x4plus.pth&response-content-type=application%2Foctet-stream [following]\n",
      "--2021-11-30 18:42:32--  https://github-releases.githubusercontent.com/387326890/08f0e941-ebb7-48f0-9d6a-73e87b710e7e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211130%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211130T184232Z&X-Amz-Expires=300&X-Amz-Signature=57eb066d49a526ea8e2a0b678053f62746782abb78e1ba3ac88249dd6eacd3fd&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=387326890&response-content-disposition=attachment%3B%20filename%3DRealESRGAN_x4plus.pth&response-content-type=application%2Foctet-stream\n",
      "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.109.154, 185.199.110.154, 185.199.111.154, ...\n",
      "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.109.154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 67040989 (64M) [application/octet-stream]\n",
      "Saving to: 'experiments/pretrained_models/RealESRGAN_x4plus.pth'\n",
      "\n",
      "100%[======================================>] 67,040,989  38.1MB/s   in 1.7s   \n",
      "\n",
      "2021-11-30 18:42:34 (38.1 MB/s) - 'experiments/pretrained_models/RealESRGAN_x4plus.pth' saved [67040989/67040989]\n",
      "\n",
      "model downloaded\n",
      "/home/u.tanielian/temp_data/Real-ESRGAN\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/\"+username.value+\"/temp_data/\"\n",
    "folder_for_gifs = \"/home/\"+username.value+\"/temp_data/\"\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "os.chdir(path)\n",
    "!hdfs dfs -get \"/user/u.tanielian/mytheresa_clip.tar\"\n",
    "!tar -xf mytheresa_clip.tar\n",
    "dataset_path = path + \"mytheresa_dalle_format/\"\n",
    "print(\"data downloaded\")\n",
    "\n",
    "os.chdir(path)\n",
    "!hdfs dfs -get \"/user/u.tanielian/01_warhol_mytheresa.pt\"\n",
    "!hdfs dfs -get \"/user/u.tanielian/02_warhol_mytheresa_timeline.pt\"\n",
    "!hdfs dfs -get \"/user/u.tanielian/vqgan_imagenet_f16_16384_model.ckpt\"\n",
    "!hdfs dfs -get \"/user/u.tanielian/vqgan_imagenet_f16_16384_configs.yaml\"\n",
    "\n",
    "os.chdir(path)\n",
    "!git clone https://github.com/tanouch/Real-ESRGAN.git\n",
    "folder = os.path.join(path, \"Real-ESRGAN\")\n",
    "os.chdir(folder)\n",
    "!wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P experiments/pretrained_models\n",
    "print(\"model downloaded\")\n",
    "    \n",
    "folder = os.path.join(path, \"Real-ESRGAN\")\n",
    "os.chdir(folder)\n",
    "print(folder)\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "from realesrgan import RealESRGANer\n",
    "    \n",
    "os.chdir(path)\n",
    "warhol_path = path + \"01_warhol_mytheresa.pt\"\n",
    "warhol_timeline_path = path + \"02_warhol_mytheresa_timeline.pt\"\n",
    "vqgan_model_path  = path + \"vqgan_imagenet_f16_16384_model.ckpt\"\n",
    "vqgan_config_path = path + \"vqgan_imagenet_f16_16384_configs.yaml\"\n",
    "srgan_model_path = path + \"Real-ESRGAN/experiments/pretrained_models/RealESRGAN_x4plus.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9ee04d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Loaded VQGAN from /home/u.tanielian/temp_data/vqgan_imagenet_f16_16384_model.ckpt and /home/u.tanielian/temp_data/vqgan_imagenet_f16_16384_configs.yaml\n",
      "True\n",
      "True\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Loaded VQGAN from /home/u.tanielian/temp_data/vqgan_imagenet_f16_16384_model.ckpt and /home/u.tanielian/temp_data/vqgan_imagenet_f16_16384_configs.yaml\n",
      "WARHOL loaded\n",
      "files loaded\n"
     ]
    }
   ],
   "source": [
    "def load_warhol_model():\n",
    "    loaded_obj = torch.load(warhol_path, map_location='cuda')\n",
    "    warhol_params, vae_params, weights = loaded_obj['hparams'], loaded_obj['vae_params'], loaded_obj['weights']\n",
    "    opt_state = loaded_obj.get('opt_state')\n",
    "    scheduler_state = loaded_obj.get('scheduler_state')\n",
    "    warhol_params = dict(**warhol_params)\n",
    "    resume_epoch = loaded_obj.get('epoch', 0)\n",
    "    USE_NEG_SAMPLES = False\n",
    "    USE_NEXT_PROD_MODULE = False\n",
    "    warhol_params[\"use_neg_samples\"] = USE_NEG_SAMPLES\n",
    "    warhol_params[\"use_next_prod_module\"] = USE_NEXT_PROD_MODULE\n",
    "\n",
    "    vae = VQGanVAE(vqgan_model_path, vqgan_config_path)\n",
    "    IMAGE_SIZE = vae.image_size\n",
    "\n",
    "    warhol = WARHOL(vae=vae, **warhol_params)\n",
    "    warhol.load_state_dict(weights)\n",
    "    warhol = warhol.cuda()\n",
    "    return warhol\n",
    "\n",
    "def load_warhol_timeline():\n",
    "    loaded_obj = torch.load(warhol_timeline_path, map_location='cuda')\n",
    "    warhol_params, vae_params, weights = loaded_obj['hparams'], loaded_obj['vae_params'], loaded_obj['weights']\n",
    "    opt_state = loaded_obj.get('opt_state')\n",
    "    scheduler_state = loaded_obj.get('scheduler_state')\n",
    "    warhol_params = dict(**warhol_params)\n",
    "    resume_epoch = loaded_obj.get('epoch', 0)\n",
    "    print(warhol_params[\"use_neg_samples\"])\n",
    "    print(warhol_params[\"use_next_prod_module\"])\n",
    "\n",
    "    vae = VQGanVAE(vqgan_model_path, vqgan_config_path)\n",
    "    IMAGE_SIZE = vae.image_size\n",
    "\n",
    "    warholTimeline = WARHOL(vae=vae, **warhol_params)\n",
    "    warholTimeline.load_state_dict(weights)\n",
    "    warholTimeline = warholTimeline.cuda()\n",
    "    return warholTimeline\n",
    "\n",
    "def load_clip_model():\n",
    "    MODELS = {\n",
    "        \"ViT-B/32\": \"https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt\",\n",
    "    }\n",
    "    print(clip.available_models())\n",
    "    model, preprocess = clip.load(\"ViT-B/32\")\n",
    "    model.to('cuda')\n",
    "    input_resolution = model.visual.input_resolution    \n",
    "    print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "    context_length = model.context_length\n",
    "    print(\"Context length:\", context_length)\n",
    "    vocab_size = model.vocab_size\n",
    "    print(\"Vocab size:\", str(vocab_size))\n",
    "    return model , input_resolution, context_length, vocab_size\n",
    "\n",
    "def infer_with_real_srgan(inputt, model_path=srgan_model_path, netscale=4, outscale=4, tile=0, tile_pad=10, pre_pad=0, \\\n",
    "                          face_enhance=False, half=True, block=23):\n",
    "        \n",
    "    if 'RealESRGAN_x4plus_anime_6B.pth' in model_path:\n",
    "        block = 6\n",
    "    elif 'RealESRGAN_x2plus.pth' in model_path:\n",
    "        netscale = 2\n",
    "\n",
    "    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=block, num_grow_ch=32, scale=netscale)\n",
    "    \n",
    "    upsampler = RealESRGANer(\n",
    "        scale=netscale,\n",
    "        model_path=model_path,\n",
    "        model=model,\n",
    "        tile=tile,\n",
    "        tile_pad=tile_pad,\n",
    "        pre_pad=pre_pad,\n",
    "        half=half)\n",
    "\n",
    "    if face_enhance:\n",
    "        from gfpgan import GFPGANer\n",
    "        face_enhancer = GFPGANer(\n",
    "            model_path='https://github.com/TencentARC/GFPGAN/releases/download/v0.2.0/GFPGANCleanv1-NoCE-C2.pth',\n",
    "            upscale=outscale,\n",
    "            arch='clean',\n",
    "            channel_multiplier=2,\n",
    "            bg_upsampler=upsampler)\n",
    "    \n",
    "    improved_images = list()\n",
    "    for idx, img in enumerate(inputt):\n",
    "        if len(img.shape) == 3 and img.shape[2] == 4:\n",
    "            img_mode = 'RGBA'\n",
    "        else:\n",
    "            img_mode = None\n",
    "\n",
    "        h, w = img.shape[0:2]\n",
    "        if max(h, w) > 1000 and netscale == 4:\n",
    "            import warnings\n",
    "            warnings.warn('The input image is large, try X2 model for better performance.')\n",
    "        if max(h, w) < 500 and netscale == 2:\n",
    "            import warnings\n",
    "            warnings.warn('The input image is small, try X4 model for better performance.')\n",
    "        \n",
    "        img = img*256\n",
    "        img = img.cpu().numpy()\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "        if face_enhance:\n",
    "            _, _, output = face_enhancer.enhance(img, has_aligned=False, only_center_face=False, paste_back=True)\n",
    "        else:\n",
    "            output, _ = upsampler.enhance(img, outscale=outscale)\n",
    "        \n",
    "        output = np.transpose(output, (2, 0, 1))/256\n",
    "        output = torch.unsqueeze(torch.from_numpy(output), 0)\n",
    "        improved_images.append(output)\n",
    "        \n",
    "    improved_images = torch.cat(improved_images, dim=0)\n",
    "    return improved_images\n",
    "\n",
    "clip_model, input_resolution, context_length, vocab_size = load_clip_model()\n",
    "print(\"CLIP loaded\")\n",
    "warhol = load_warhol_model()\n",
    "warholTimeline = load_warhol_timeline()\n",
    "print(\"WARHOL loaded\")\n",
    "\n",
    "batch_size = 1\n",
    "from pathlib import Path\n",
    "path_folder = Path(dataset_path)\n",
    "clip_files = [*path_folder.glob('**/*.npy')]\n",
    "clip_files = sorted(list({clip_file.stem: clip_file for clip_file in clip_files}))\n",
    "im_clip_embs = torch.cat([torch.from_numpy(np.load(dataset_path+file+\".npy\"))[:512].unsqueeze(1) for file in clip_files], dim=1).cuda()\n",
    "im_files = [*path_folder.glob('**/*.jpg')]\n",
    "im_files = sorted(list({im_file.stem: im_file for im_file in im_files}))\n",
    "im_files = [dataset_path+file+\".jpg\" for file in im_files]\n",
    "print(\"files loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c83de46-23d7-4e3d-879c-217e7128cebb",
   "metadata": {},
   "source": [
    "## Demo !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69af608f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c4d8da8147473983940034a3fd7ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='Red high heels shoes', description='query'), IntSlider(value=4, description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf468237c4bd437fbdfdc1f46c53f6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=False, description='Content based', indent=False), Checkbox(value=False, descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "home_folder = os.getcwd()\n",
    "from PIL import Image\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "\n",
    "def showbig2(img, topk):\n",
    "    npimg = img.cpu().numpy()\n",
    "    npimg = np.clip(npimg, 0, 1)\n",
    "    fig = plt.figure(figsize=(topk*10, 3.))\n",
    "    ax = fig.add_subplot(111)\n",
    "    data = np.transpose(npimg, (1, 2, 0))\n",
    "    ax.imshow(data)\n",
    "    ax.set_axis_off()\n",
    "    ax.set_aspect(1)\n",
    "\n",
    "    \n",
    "def get_text_embedding_from_prompt(model, text_prompt):\n",
    "    texts = []\n",
    "    text_tokens = []\n",
    "    \n",
    "    text_tokens.append(tokenizer.encode(text_prompt))\n",
    "    texts.append(str(text_prompt))\n",
    "\n",
    "    text_input = torch.zeros(1, model.context_length, dtype=torch.long)\n",
    "    sot_token = tokenizer.encoder['<|startoftext|>']\n",
    "    eot_token = tokenizer.encoder['<|endoftext|>']\n",
    "\n",
    "    for i, tokens in enumerate(text_tokens):\n",
    "        tokens = [sot_token] + tokens + [eot_token]\n",
    "        text_input[i, :len(tokens)] = torch.tensor(tokens)\n",
    "\n",
    "    text_input = text_input.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        text_features = model.encode_text(text_input).float()\n",
    "\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    text_embedding = text_features\n",
    "    return text_embedding\n",
    "    \n",
    "    \n",
    "def output_txt_and_im_emb(im_clip_embs, prompt_text, topk):\n",
    "    ###GET QUERY EMB\n",
    "    txt_emb = get_text_embedding_from_prompt(clip_model, prompt_text).cuda()\n",
    "    im_clip_embs = im_clip_embs.float()\n",
    "    dot_product = torch.reshape(torch.matmul(txt_emb, im_clip_embs), (-1,))\n",
    "    (values, indices) = torch.topk(dot_product, topk)\n",
    "    target_img = [transforms.ToTensor()(Image.open(im_files[index])).unsqueeze_(0).cuda() for index in indices]\n",
    "    target_img = torch.cat(target_img, dim=0)\n",
    "    target_im_emb = torch.t(torch.index_select(im_clip_embs, dim=1, index=indices)).unsqueeze(1)\n",
    "    txt_emb = torch.cat([txt_emb.unsqueeze(0)]*topk, dim=0)\n",
    "    return target_img, target_im_emb, txt_emb\n",
    "\n",
    "    \n",
    "def get_closest_prods(query,topk):\n",
    "    target_img, target_im_emb, txt_emb = output_txt_and_im_emb(im_clip_embs, prompt_text=query, topk=topk)\n",
    "    qgrid = make_grid(target_img, nrow=topk)\n",
    "    showbig2(qgrid, topk)\n",
    "    return target_img, target_im_emb, txt_emb, topk, query\n",
    "    \n",
    "    \n",
    "def generate_prods(model_list, target_img, target_im_emb, txt_emb, temp, topk, \\\n",
    "                   num_images_sampled, nrow, prefix):\n",
    "    gen_images = list()\n",
    "    gen_images_np = list()\n",
    "    gen_texts = list()\n",
    "    clip_sims = list()\n",
    "    \n",
    "    for i in tqdm(range(num_images_sampled)): \n",
    "        for m in range(len(model_list)):\n",
    "            model = model_list[m]\n",
    "            text_tokens, gen_text = model.generate_texts(target_im_emb, txt_emb, temperature = temp)\n",
    "            gen_image = model.generate_images(target_im_emb, txt_emb, text_tokens, temperature = temp)\n",
    "            gen_image = F.interpolate(gen_image, size=224)\n",
    "            gen_images.append(gen_image)\n",
    "            gen_images_np.append(gen_image.cpu().numpy())\n",
    "\n",
    "            #Get CLIP embedding of gen_image and compute sim with query img and query txt\n",
    "            im_embed = clip_model.encode_image(gen_image).float()\n",
    "            im_embed = im_embed/im_embed.norm(dim=-1, keepdim=True)\n",
    "            img_clip_sim = (torch.diag(torch.matmul(im_embed, torch.t(target_im_emb.squeeze(1)))).cpu().detach().numpy())\n",
    "            txt_clip_sim = (torch.diag(torch.matmul(im_embed, torch.t(txt_emb.squeeze(1)))).cpu().detach().numpy())\n",
    "            clip_sims.append(txt_clip_sim)\n",
    "                \n",
    "            #Get generated text\n",
    "            new_texts = list()\n",
    "            every = 5\n",
    "            for i in range(len(gen_image)):\n",
    "                text = gen_text[i]\n",
    "                splitted_str = text.split(\" \")[:20]\n",
    "                splitted_str = [\" \".join(splitted_str[i:i+every]) for i in range(0, len(splitted_str), every)]\n",
    "                splitted_str = \"Cosine.Sim: \" + str(img_clip_sim[i]) +\"\\n\" + \"\\n\".join(splitted_str)+\"[...]\"\n",
    "                new_texts.append(splitted_str)\n",
    "            gen_texts.append(new_texts)\n",
    "            \n",
    "            #Display current generation\n",
    "            width = nrow*5.5\n",
    "            height = nrow*2.5\n",
    "            fig = plt.figure(figsize=(width, 6))\n",
    "            if m==0:\n",
    "                print(\"\\nContent-optimized generation: Products are optimized to be visually similar with the query product\\n\\n\")\n",
    "            else:\n",
    "                print(\"\\nUser-optimized generation: Products are optimized to be relevant to the users of the query product\\n\\n\")\n",
    "            \n",
    "            gen_image = infer_with_real_srgan(gen_image, netscale=4, outscale=3.5)\n",
    "            for i in range(len(gen_image)):\n",
    "                ax = fig.add_subplot(1, nrow, i+1)\n",
    "                ax.set_title(new_texts[i], fontsize=nrow*4.5)\n",
    "                ax.set_axis_off()\n",
    "\n",
    "                npimg = gen_image.cpu().numpy()[i]\n",
    "                npimg = np.clip(npimg, 0, 1)\n",
    "                img_data = np.transpose(npimg, (1, 2, 0))\n",
    "                ax.imshow(img_data)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "    #Final image\n",
    "    if len(model_list)==1 and num_images_sampled>1:\n",
    "        fig = plt.figure(figsize=(width, 6))\n",
    "        print(\"\\n Showing the best generation !!\\n\")\n",
    "        for i in range(len(gen_image)):\n",
    "            j = np.argmax(np.array(clip_sims)[:,i])\n",
    "            ax = fig.add_subplot(1, nrow, i+1)\n",
    "            ax.set_title(np.array(gen_texts)[j,i], fontsize=nrow*4.5)\n",
    "            ax.set_axis_off()\n",
    "\n",
    "            npimg = np.array(gen_images_np)[j, i]\n",
    "            npimg = np.clip(npimg, 0, 1)\n",
    "            img_data = np.transpose(npimg, (1, 2, 0))\n",
    "            ax.imshow(img_data)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "def generate_from_ui(query_tp, content_based, user_based, num_results, temp):\n",
    "    models = list()\n",
    "    if content_based:\n",
    "        models.append(warhol)\n",
    "    if user_based:\n",
    "        models.append(warholTimeline)\n",
    "    target_img, target_img_emb, txt_emb, topk, query = my_result.result\n",
    "    generate_prods(models, target_img, target_img_emb, txt_emb, \\\n",
    "                   temp, topk=topk, num_images_sampled=num_results, nrow=topk, prefix=\"WARHOL_\")\n",
    "    \n",
    "topk_slider = widgets.IntSlider(\n",
    "         value=4,\n",
    "         description='Num items:',\n",
    "         min=3,\n",
    "         max=6,\n",
    "         step=1)\n",
    "\n",
    "my_result = interactive(get_closest_prods, query=(\"Red high heels shoes\"), \\\n",
    "                        topk=topk_slider)\n",
    "display(my_result)\n",
    "\n",
    "num_results_slider = widgets.FloatSlider(\n",
    "         value=1,\n",
    "         description='Samples:',\n",
    "         min=1,\n",
    "         max=10,\n",
    "         step=1)\n",
    "\n",
    "temp_slider = widgets.FloatSlider(\n",
    "         value=0.4,\n",
    "         description='Temperature:',\n",
    "         min=0.1,\n",
    "         max=1.0,\n",
    "         step=0.1,)\n",
    "\n",
    "query_with_prompt = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Query with text prompt',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "content_based = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Content based',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "user_based = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='User based',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "button = widgets.Button(description='Generate!')\n",
    "button100 = widgets.Button(description='Generate gifs !')\n",
    "out = widgets.Output()\n",
    "\n",
    "def on_button_clicked(_):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        generate_from_ui(query_with_prompt.value, content_based.value, user_based.value, \\\n",
    "                                  int(num_results_slider.value), temp_slider.value)\n",
    "\n",
    "# linking button and function together using a button's method\n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "# displaying button and its output together\n",
    "widgets.VBox([content_based, user_based, num_results_slider, temp_slider, button, out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b670dd8-4adc-45ae-b9c7-298117e477c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "warhol",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
